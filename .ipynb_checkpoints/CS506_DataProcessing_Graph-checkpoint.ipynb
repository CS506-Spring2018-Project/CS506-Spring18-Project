{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS506 Project Main Report\n",
    "\n",
    "## Chengyu Deng, Xiaotong Niu, Qian Zhang\n",
    "\n",
    "This Jupyter Notebook is the code for the CS506 Initial Report. We processed the main data set and make it ready to use for analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 Data processing**\n",
    "\n",
    "We used Building Energy Reporting And Disclosure Ordinance (BERDO) data provided by [Analyze Boston - Boston.gov](https://data.boston.gov/) to do the analysis. \n",
    "* **_berdo2017.csv_** for the year of 2017.\n",
    "* **_2016-reported-energy-and-water-metrics.xlsx_** for the year of 2016.\n",
    "* **_2015-reported-energy-and-water-metrics.xlsx_** for the year of 2015.\n",
    "\n",
    "The source of the data is: https://data.boston.gov/dataset/building-energy-reporting-and-disclosure-ordinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put data into Pandas dataframes\n",
    "\n",
    "# 2015 xlsx -> csv\n",
    "data_2015_xlsx = pd.read_excel('2015-reported-energy-and-water-metrics.xlsx', index_col=None)\n",
    "data_2015_xlsx.to_csv('berdo2015.csv')\n",
    "\n",
    "# 2016 xlsx -> csv\n",
    "data_2016_xlsx = pd.read_excel('2016-reported-energy-and-water-metrics.xlsx', index_col=None)\n",
    "data_2016_xlsx.to_csv('berdo2016.csv')\n",
    "\n",
    "# 2017\n",
    "df_2015 = pd.read_csv('berdo2015.csv')\n",
    "df_2016 = pd.read_csv('berdo2016.csv')\n",
    "df_2017 = pd.read_csv('berdo2017.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print(type(df_2015))\n",
    "# print(type(df_2016))\n",
    "# print(type(df_2017))\n",
    "# print('-------------------------------')\n",
    "# print(df_2015.shape)\n",
    "# print(df_2016.shape)\n",
    "# print(df_2017.shape)\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2015.columns.values))\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2016.columns.values))\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2017.columns.values))\n",
    "# print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Trimming\n",
    "\n",
    "# Dataframe columns names handling\n",
    "if 'Years Reported' in df_2016:\n",
    "    df_2016.drop('Years Reported', axis = 1, inplace = True)\n",
    "if 'Years Reported' in df_2017:\n",
    "    df_2017.drop('Years Reported', axis = 1, inplace = True)\n",
    "\n",
    "if ' Gross Area (sq ft) ' in df_2017:\n",
    "    df_2017.rename(index=str, columns={' Gross Area (sq ft) ': 'Gross Area (sq ft)'}, inplace = True)\n",
    "if ' GHG Emissions (MTCO2e) ' in df_2017:\n",
    "    df_2017.rename(index=str, columns={' GHG Emissions (MTCO2e) ': 'GHG Emissions (MTCO2e)'}, inplace = True)\n",
    "if ' Total Site Energy (kBTU) ' in df_2017:\n",
    "    df_2017.rename(index=str, columns={' Total Site Energy (kBTU) ': 'Total Site Energy (kBTU)'}, inplace = True)\n",
    "if ' Onsite Renewable (kWh) ' in df_2017:\n",
    "    df_2017.rename(index=str, columns={' Onsite Renewable (kWh) ': 'Onsite Renewable (kWh)'}, inplace = True)\n",
    "\n",
    "    \n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print(type(df_2015))\n",
    "# print(type(df_2016))\n",
    "# print(type(df_2017))\n",
    "# print(df_2015.shape)\n",
    "# print(df_2016.shape)\n",
    "# print(df_2017.shape)\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2015.columns.values))\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2016.columns.values))\n",
    "# print('-------------------------------')\n",
    "# print(list(df_2017.columns.values))\n",
    "# print('-------------------------------')\n",
    "\n",
    "\n",
    "# Select properties which belong to BU\n",
    "with open(\"BU_Property_List.csv\", 'r') as propertyFile:\n",
    "    reader = csv.reader(propertyFile, delimiter='\\t')\n",
    "    propertyList_convol = list(reader)\n",
    "    \n",
    "    propertyList = []\n",
    "    for each in propertyList_convol:\n",
    "        for element in each:\n",
    "            propertyList.append(element)\n",
    "            \n",
    "df2015_BU = df_2015.loc[df_2015['Property Name'].isin(propertyList)]\n",
    "df2016_BU = df_2016.loc[df_2016['Property Name'].isin(propertyList)]\n",
    "df2017_BU = df_2017.loc[df_2017['Property Name'].isin(propertyList)]\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "print('BU properties ------------------------------------')\n",
    "print(df2015_BU.shape)\n",
    "print(df2016_BU.shape)\n",
    "print(df2017_BU.shape)\n",
    "\n",
    "# Drop rows of data whose Site EUI (kBTU/sf) is not available\n",
    "\n",
    "df2015_BU = df2015_BU.loc[df_2015['Site EUI (kBTU/sf)'] != 'Not Available']\n",
    "df2016_BU = df2016_BU.loc[df_2016['Site EUI (kBTU/sf)'] != 'Not Available']\n",
    "df2017_BU = df2017_BU.loc[df_2017['Site EUI (kBTU/sf)'] != 'Not Available']\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print(len(propertyList))\n",
    "# print('------------------------------------')\n",
    "# print(propertyList)\n",
    "# print('------------------------------------')\n",
    "# # print(df2015_BU)\n",
    "# # print(df2016_BU)\n",
    "# # print(df2017_BU)\n",
    "print('BU properties Site EUI (kBTU/sf)] != Not Available----')\n",
    "print(df2015_BU.shape)\n",
    "print(df2016_BU.shape)\n",
    "print(df2017_BU.shape)\n",
    "print('------------------------------------')\n",
    "print(list(df_2015.columns.values))\n",
    "print('------------------------------------')\n",
    "# print(df2015_BU['Property Name'])\n",
    "# print(df2016_BU['Property Name'])\n",
    "# print(df2017_BU['Property Name'])\n",
    "# print('------------------------------------')\n",
    "# print(df2017_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', '% Steam']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part 2 Monthly energy consumption assignment**\n",
    "\n",
    "Since the BERDO data is yearly based, we need to calculate the monthly energy consumption for each building based on the energy consumption distribution provided by Kevin Zheng from Sustainability@BU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate monthly energy consumption electricity/natrual gas\n",
    "\n",
    "#[Jan, Feb, Mar, ..., Nov, Dec]\n",
    "share_2015 = np.array([0.2038, 0.1062, 0.0778, 0.0620, 0.0589, 0.0588, 0.0473, 0.0813, 0.0705, 0.0732, 0.0673, 0.0929])\n",
    "share_2016 = np.array([0.0919, 0.1179, 0.0995, 0.0642, 0.0710, 0.0733, 0.0660, 0.0673, 0.0733, 0.0774, 0.0959, 0.1023])\n",
    "share_2017 = np.array([0.1146, 0.1031, 0.0872, 0.0862, 0.0699, 0.0650, 0.0661, 0.0635, 0.0865, 0.0671, 0.0727, 0.1181])\n",
    "\n",
    "#          Jan                               Dec\n",
    "#[[Natural Gas, Electricity], ...[Natural Gas, Electricity]]\n",
    "NESplits_2015 = np.array(\n",
    "    [[0.6877, 0.3123], \n",
    "     [0.6654, 0.3346], \n",
    "     [0.6079, 0.3921], \n",
    "     [0.5086, 0.4914], \n",
    "     [0.3888, 0.6112], \n",
    "     [0.3663, 0.6337], \n",
    "     [0.1913, 0.8087], \n",
    "     [0.5173, 0.4827], \n",
    "     [0.5090, 0.4910], \n",
    "     [0.5598, 0.4402], \n",
    "     [0.5245, 0.4755], \n",
    "     [0.6743, 0.3257]])\n",
    "\n",
    "NESplits_2016 = np.array(\n",
    "    [[0.6519, 0.3481], \n",
    "     [0.6802, 0.3198], \n",
    "     [0.6496, 0.3504], \n",
    "     [0.5395, 0.4605], \n",
    "     [0.4350, 0.5650], \n",
    "     [0.4154, 0.5846], \n",
    "     [0.3339, 0.6661], \n",
    "     [0.3336, 0.6664], \n",
    "     [0.4442, 0.5558], \n",
    "     [0.5321, 0.4679], \n",
    "     [0.6225, 0.3775], \n",
    "     [0.6477, 0.3523]])\n",
    "\n",
    "NESplits_2017 = np.array(\n",
    "    [[0.6739, 0.3261], \n",
    "     [0.6707, 0.3293], \n",
    "     [0.6211, 0.3789], \n",
    "     [0.5920, 0.4080], \n",
    "     [0.5074, 0.4926], \n",
    "     [0.3905, 0.6095], \n",
    "     [0.3199, 0.6801], \n",
    "     [0.3178, 0.6822],\n",
    "     [0.3672, 0.6328], \n",
    "     [0.3960, 0.6040],  \n",
    "     [0.5386, 0.4614], \n",
    "     [0.6525, 0.3475]])\n",
    "\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "# print(np.sum(share_2015))\n",
    "# print(np.sum(share_2016))\n",
    "# print(np.sum(share_2017))\n",
    "# print('------------------------------------')\n",
    "# print(np.sum(NESplits_2015))\n",
    "# print(np.sum(NESplits_2016))\n",
    "# print(np.sum(NESplits_2017))\n",
    "# print('------------------------------------')\n",
    "# print(share_2015.shape) -> (12, )\n",
    "# print(share_2016.shape) -> (12, )\n",
    "# print(share_2017.shape) -> (12, )\n",
    "\n",
    "# Change (12, ) to (12, 1) since the we can not do matrix multiplication with shape (12, ) \n",
    "share_2015 = np.reshape(share_2015, (share_2015.shape[0], 1))\n",
    "share_2016 = np.reshape(share_2016, (share_2016.shape[0], 1))\n",
    "share_2017 = np.reshape(share_2017, (share_2017.shape[0], 1))\n",
    "\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(share_2015.shape)\n",
    "# print(share_2016.shape)\n",
    "# print(share_2017.shape)\n",
    "# print('------------------------------------')\n",
    "# print(NESplits_2015.shape)\n",
    "# print(NESplits_2016.shape)\n",
    "# print(NESplits_2017.shape)\n",
    "\n",
    "share_2015_G_E = share_2015 * NESplits_2015\n",
    "share_2016_G_E = share_2016 * NESplits_2016\n",
    "share_2017_G_E = share_2017 * NESplits_2017\n",
    "\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(share_2015_G_E.shape)\n",
    "# print(share_2016_G_E.shape)\n",
    "# print(share_2017_G_E.shape)\n",
    "# print(share_2015_G_E)\n",
    "# print(share_2016_G_E)\n",
    "# print(share_2017_G_E)\n",
    "# print('------------------------------------')\n",
    "\n",
    "# print(np.sum(share_2015_G_E, axis = 1))\n",
    "# print(np.sum(share_2016_G_E, axis = 1))\n",
    "# print(np.sum(share_2017_G_E, axis = 1))\n",
    "\n",
    "# Normalize the seperated distribution of electircity/natrual gas comsumption\n",
    "G_dstri_2015 = share_2015_G_E[:, 0]\n",
    "E_dstri_2015 = share_2015_G_E[:, 1]\n",
    "\n",
    "G_dstri_2016 = share_2016_G_E[:, 0]\n",
    "E_dstri_2016 = share_2016_G_E[:, 1]\n",
    "\n",
    "G_dstri_2017 = share_2017_G_E[:, 0]\n",
    "E_dstri_2017 = share_2017_G_E[:, 1]\n",
    "\n",
    "# Reshape from (12, ) to (12, 1)\n",
    "G_dstri_2015 = np.reshape(G_dstri_2015, (G_dstri_2015.shape[0], 1))\n",
    "E_dstri_2015 = np.reshape(E_dstri_2015, (E_dstri_2015.shape[0], 1))\n",
    "\n",
    "G_dstri_2016 = np.reshape(G_dstri_2016, (G_dstri_2016.shape[0], 1))\n",
    "E_dstri_2016 = np.reshape(E_dstri_2016, (E_dstri_2016.shape[0], 1))\n",
    "\n",
    "G_dstri_2017 = np.reshape(G_dstri_2017, (G_dstri_2017.shape[0], 1))\n",
    "E_dstri_2017 = np.reshape(E_dstri_2017, (E_dstri_2017.shape[0], 1))\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(share_2015_G_E)\n",
    "# print(G_dstri_2015)\n",
    "# print(E_dstri_2015)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(share_2016_G_E)\n",
    "# print(G_dstri_2016)\n",
    "# print(E_dstri_2016)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(share_2017_G_E)\n",
    "# print(G_dstri_2017)\n",
    "# print(E_dstri_2017)\n",
    "\n",
    "G_dstri_2015_Norm = normalize(G_dstri_2015, norm='l1', axis = 0)\n",
    "E_dstri_2015_Norm = normalize(E_dstri_2015, norm='l1', axis = 0)\n",
    "\n",
    "G_dstri_2016_Norm = normalize(G_dstri_2016, norm='l1', axis = 0)\n",
    "E_dstri_2016_Norm = normalize(E_dstri_2016, norm='l1', axis = 0)\n",
    "\n",
    "G_dstri_2017_Norm = normalize(G_dstri_2017, norm='l1', axis = 0)\n",
    "E_dstri_2017_Norm = normalize(E_dstri_2017, norm='l1', axis = 0)\n",
    "\n",
    "# print('------------------------------------')\n",
    "# print(G_dstri_2015_Norm)\n",
    "# print('------------------------------------')\n",
    "# print(E_dstri_2015_Norm)\n",
    "# print('------------------------------------')\n",
    "# print(G_dstri_2016_Norm)\n",
    "# print('------------------------------------')\n",
    "# print(E_dstri_2016_Norm)\n",
    "# print('------------------------------------')\n",
    "# print(G_dstri_2017_Norm)\n",
    "# print('------------------------------------')\n",
    "# print(E_dstri_2017_Norm)\n",
    "# print('------------------------------------')\n",
    "\n",
    "# print(np.sum(G_dstri_2015_Norm))\n",
    "# print(np.sum(E_dstri_2015_Norm))\n",
    "# print(np.sum(G_dstri_2016_Norm))\n",
    "# print(np.sum(E_dstri_2016_Norm))\n",
    "# print(np.sum(G_dstri_2017_Norm))\n",
    "# print(np.sum(E_dstri_2017_Norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One more data trim... \n",
    "'''\n",
    "Since the distribution only involve with gas and electricity, we CURRENTLY drop the buildings that use steam. \n",
    "However in the future, if we get the revised consumption distribution over electricity, gas and steam, we will\n",
    "re-include those dropped buildings that use steam back to analysis. \n",
    "'''\n",
    "\n",
    "# Be careful that in 2015, 2017 data is in format of xx% while in 2016 it is 0.xx. \n",
    "# Those are all strings in dataframe, need to convert to numerical before calculation (monthly consumption assignment)\n",
    "\n",
    "df2015_BU = df2015_BU.loc[df2015_BU['% Steam'] == '0%']\n",
    "df2016_BU = df2016_BU.loc[df2016_BU['% Steam'].isnull()]\n",
    "df2017_BU = df2017_BU.loc[df2017_BU['% Steam'].isnull()]\n",
    "\n",
    "\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "print('-----2015----------------------------')\n",
    "print(df2015_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', '% Steam']])\n",
    "print('-----2016----------------------------')\n",
    "print(df2016_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', '% Steam']])\n",
    "print('-----2017----------------------------')\n",
    "print(df2017_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', '% Steam']])\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assignment of montly data \n",
    "\n",
    "# Convert Site EUI (kBTU/sf) to float\n",
    "df2015_BU['Site EUI (kBTU/sf)'] = pd.to_numeric(df2015_BU['Site EUI (kBTU/sf)'], errors='coerce')\n",
    "df2016_BU['Site EUI (kBTU/sf)'] = pd.to_numeric(df2016_BU['Site EUI (kBTU/sf)'], errors='coerce')\n",
    "df2017_BU['Site EUI (kBTU/sf)'] = pd.to_numeric(df2017_BU['Site EUI (kBTU/sf)'], errors='coerce')\n",
    "\n",
    "# print(type(df2015_BU.loc[52, '% Electricity']))\n",
    "# print(type(df2017_BU.loc['1654', '% Electricity']))\n",
    "\n",
    "# Convert '% Electricity', '% Gas' to float\n",
    "# Remove % in 2015, 2017 (2016 does not have % at the end of string)\n",
    "\n",
    "# print(df2015_BU['% Electricity'])\n",
    "\n",
    "df2015_BU['% Electricity'] = df2015_BU['% Electricity'].str.replace('%', '')\n",
    "df2017_BU['% Electricity'] = df2017_BU['% Electricity'].str.replace('%', '')\n",
    "\n",
    "df2015_BU['% Gas'] = df2015_BU['% Gas'].str.replace('%', '')\n",
    "df2017_BU['% Gas'] = df2017_BU['% Gas'].str.replace('%', '')\n",
    "\n",
    "\n",
    "# Fill NaN with 0\n",
    "df2015_BU[['% Electricity', '% Gas']] = df2015_BU[['% Electricity', '% Gas']].fillna(0)\n",
    "df2016_BU[['% Electricity', '% Gas']] = df2016_BU[['% Electricity', '% Gas']].fillna(0)\n",
    "df2017_BU[['% Electricity', '% Gas']] = df2017_BU[['% Electricity', '% Gas']].fillna(0)\n",
    "\n",
    "# To float\n",
    "df2015_BU['% Electricity'] = pd.to_numeric(df2015_BU['% Electricity'], errors='coerce') / 100\n",
    "df2016_BU['% Electricity'] = pd.to_numeric(df2016_BU['% Electricity'], errors='coerce')\n",
    "df2017_BU['% Electricity'] = pd.to_numeric(df2017_BU['% Electricity'], errors='coerce') / 100\n",
    "\n",
    "df2015_BU['% Gas'] = pd.to_numeric(df2015_BU['% Gas'], errors='coerce') / 100\n",
    "df2016_BU['% Gas'] = pd.to_numeric(df2016_BU['% Gas'], errors='coerce') \n",
    "df2017_BU['% Gas'] = pd.to_numeric(df2017_BU['% Gas'], errors='coerce') / 100\n",
    "\n",
    "\n",
    "# Calculate yearly electricity and gas consumption (in kBTU/sf) based on 'Site EUI (kBTU/sf)'\n",
    "df2015_BU['G_EUI'] = df2015_BU['Site EUI (kBTU/sf)'] * df2015_BU['% Gas']\n",
    "df2015_BU['E_EUI'] = df2015_BU['Site EUI (kBTU/sf)'] * df2015_BU['% Electricity']\n",
    "\n",
    "df2016_BU['G_EUI'] = df2016_BU['Site EUI (kBTU/sf)'] * df2016_BU['% Gas']\n",
    "df2016_BU['E_EUI'] = df2016_BU['Site EUI (kBTU/sf)'] * df2016_BU['% Electricity']\n",
    "\n",
    "df2017_BU['G_EUI'] = df2017_BU['Site EUI (kBTU/sf)'] * df2017_BU['% Gas']\n",
    "df2017_BU['E_EUI'] = df2017_BU['Site EUI (kBTU/sf)'] * df2017_BU['% Electricity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing code (For debugging purpose)\n",
    "# print('-----2015----------------------------')\n",
    "# print(df2015_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', 'E_EUI', 'G_EUI', ]])\n",
    "# print('-----2016----------------------------')\n",
    "# print(df2016_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', 'E_EUI', 'G_EUI', ]])\n",
    "# print('-----2017----------------------------')\n",
    "# print(df2017_BU[['Site EUI (kBTU/sf)', '% Electricity', '% Gas', 'E_EUI', 'G_EUI', ]])\n",
    "# print('----------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Monthly distribution of Gas EUI in each BU property in 2015\n",
    "df2015_BU['G_Jan'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[0] \n",
    "df2015_BU['G_Feb'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[1] \n",
    "df2015_BU['G_Mar'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[2]\n",
    "df2015_BU['G_Apr'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[3] \n",
    "df2015_BU['G_May'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[4]\n",
    "df2015_BU['G_Jun'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[5]\n",
    "df2015_BU['G_Jul'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[6]\n",
    "df2015_BU['G_Aug'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[7]\n",
    "df2015_BU['G_Sep'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[8]\n",
    "df2015_BU['G_Oct'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[9]\n",
    "df2015_BU['G_Nov'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[10] \n",
    "df2015_BU['G_Dec'] = df2015_BU['G_EUI'] * G_dstri_2015_Norm[11] \n",
    "\n",
    "\n",
    "#Monthly distribution of Electricity EUI in each BU property in 2015\n",
    "df2015_BU['E_Jan'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[0] \n",
    "df2015_BU['E_Feb'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[1] \n",
    "df2015_BU['E_Mar'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[2]\n",
    "df2015_BU['E_Apr'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[3] \n",
    "df2015_BU['E_May'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[4]\n",
    "df2015_BU['E_Jun'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[5]\n",
    "df2015_BU['E_Jul'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[6]\n",
    "df2015_BU['E_Aug'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[7]\n",
    "df2015_BU['E_Sep'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[8]\n",
    "df2015_BU['E_Oct'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[9]\n",
    "df2015_BU['E_Nov'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[10] \n",
    "df2015_BU['E_Dec'] = df2015_BU['E_EUI'] * E_dstri_2015_Norm[11] \n",
    "\n",
    "\n",
    "#Monthly distribution of Gas EUI in each BU property in 2016\n",
    "df2016_BU['G_Jan'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[0] \n",
    "df2016_BU['G_Feb'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[1] \n",
    "df2016_BU['G_Mar'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[2]\n",
    "df2016_BU['G_Apr'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[3] \n",
    "df2016_BU['G_May'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[4]\n",
    "df2016_BU['G_Jun'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[5]\n",
    "df2016_BU['G_Jul'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[6]\n",
    "df2016_BU['G_Aug'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[7]\n",
    "df2016_BU['G_Sep'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[8]\n",
    "df2016_BU['G_Oct'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[9]\n",
    "df2016_BU['G_Nov'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[10] \n",
    "df2016_BU['G_Dec'] = df2016_BU['G_EUI'] * G_dstri_2016_Norm[11] \n",
    "\n",
    "#Monthly distribution of Electricity EUI in each BU property in 2016\n",
    "df2016_BU['E_Jan'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[0] \n",
    "df2016_BU['E_Feb'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[1] \n",
    "df2016_BU['E_Mar'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[2]\n",
    "df2016_BU['E_Apr'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[3] \n",
    "df2016_BU['E_May'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[4]\n",
    "df2016_BU['E_Jun'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[5]\n",
    "df2016_BU['E_Jul'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[6]\n",
    "df2016_BU['E_Aug'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[7]\n",
    "df2016_BU['E_Sep'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[8]\n",
    "df2016_BU['E_Oct'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[9]\n",
    "df2016_BU['E_Nov'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[10] \n",
    "df2016_BU['E_Dec'] = df2016_BU['E_EUI'] * E_dstri_2016_Norm[11] \n",
    "\n",
    "#Monthly distribution of Gas EUI in each BU property in 2017\n",
    "df2017_BU['G_Jan'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[0] \n",
    "df2017_BU['G_Feb'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[1] \n",
    "df2017_BU['G_Mar'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[2]\n",
    "df2017_BU['G_Apr'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[3] \n",
    "df2017_BU['G_May'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[4]\n",
    "df2017_BU['G_Jun'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[5]\n",
    "df2017_BU['G_Jul'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[6]\n",
    "df2017_BU['G_Aug'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[7]\n",
    "df2017_BU['G_Sep'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[8]\n",
    "df2017_BU['G_Oct'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[9]\n",
    "df2017_BU['G_Nov'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[10] \n",
    "df2017_BU['G_Dec'] = df2017_BU['G_EUI'] * G_dstri_2017_Norm[11] \n",
    "\n",
    "#Monthly distribution of Electricity EUI in each BU property in 2017\n",
    "df2017_BU['E_Jan'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[0] \n",
    "df2017_BU['E_Feb'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[1] \n",
    "df2017_BU['E_Mar'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[2]\n",
    "df2017_BU['E_Apr'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[3] \n",
    "df2017_BU['E_May'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[4]\n",
    "df2017_BU['E_Jun'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[5]\n",
    "df2017_BU['E_Jul'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[6]\n",
    "df2017_BU['E_Aug'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[7]\n",
    "df2017_BU['E_Sep'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[8]\n",
    "df2017_BU['E_Oct'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[9]\n",
    "df2017_BU['E_Nov'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[10] \n",
    "df2017_BU['E_Dec'] = df2017_BU['E_EUI'] * E_dstri_2017_Norm[11] \n",
    "\n",
    "\n",
    "MonthColumnList_E = ['E_Jan','E_Feb','E_Mar','E_Apr','E_May','E_Jun','E_Jul','E_Aug','E_Sep','E_Oct','E_Nov','E_Dec']\n",
    "MonthColumnList_G = ['G_Jan','G_Feb','G_Mar','G_Apr','G_May','G_Jun','G_Jul','G_Aug','G_Sep','G_Oct','G_Nov','G_Dec']\n",
    "MonthColumnList_T = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "\n",
    "# Testing code (For debugging purpose)\n",
    "\n",
    "# print('--------------2015----------------------------')\n",
    "# print('Monthly distribution of gas EUI in BU properties in 2015')\n",
    "# print(df2015_BU[MonthColumnList_G])\n",
    "# print('Monthly distribution of electricity EUI in BU properties in 2015')\n",
    "# print(df2015_BU[MonthColumnList_E])\n",
    "# print('--------------2016----------------------------')\n",
    "# print('Monthly distribution of gas EUI in BU properties in 2016')\n",
    "# print(df2016_BU[MonthColumnList_G])\n",
    "# print('Monthly distribution of electricity EUI in BU properties in 2016')\n",
    "# print(df2016_BU[MonthColumnList_E])\n",
    "# print('--------------2017----------------------------')\n",
    "# print('Monthly distribution of gas EUI in BU properties in 2017')\n",
    "# print(df2017_BU[MonthColumnList_G])\n",
    "# print('Monthly distribution of electricity EUI in BU properties in 2017')\n",
    "# print(df2017_BU[MonthColumnList_E])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 Visualization of monthly energy consumption**\n",
    "\n",
    "Visualize the processed data and be ready to do further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "\n",
    "# Visualize:\n",
    "\n",
    "# Gas Distribution\n",
    "month = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, G_dstri_2015_Norm*100, ms = 5, label = 'Gas usage distribution 2015')\n",
    "ax.plot(month, G_dstri_2016_Norm*100, ms = 5, label = 'Gas usage distribution 2016')\n",
    "ax.plot(month, G_dstri_2017_Norm*100, ms = 5, label = 'Gas usage distribution 2017')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Gas consumption Distribution over month in 2015, 2016, and 2017')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Month')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electricity Distribution\n",
    "month = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, E_dstri_2015_Norm*100, ms = 5, label = 'Electricity usage distribution 2015')\n",
    "ax.plot(month, E_dstri_2016_Norm*100, ms = 5, label = 'Electricity usage distribution 2016')\n",
    "ax.plot(month, E_dstri_2017_Norm*100, ms = 5, label = 'Electricity usage distribution 2017')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Electricity consumption Distribution over month in 2015, 2016, and 2017')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample building\n",
    "\n",
    "#2015: 192\n",
    "buildingName_2015 = \"Building A\"\n",
    "building_2015_sample_G = df2015_BU.loc[192, MonthColumnList_G]\n",
    "building_2015_sample_E = df2015_BU.loc[192, MonthColumnList_E]\n",
    "\n",
    "\n",
    "#2016: 306 \n",
    "buildingName_2016 = \"Building B\"\n",
    "building_2016_sample_G = df2016_BU.loc[172, MonthColumnList_G]\n",
    "building_2016_sample_E = df2016_BU.loc[172, MonthColumnList_E]\n",
    "\n",
    "#2017: 1689 (2017 The row index is string)\n",
    "buildingName_2017 = \"Building C\"\n",
    "building_2017_sample_G = df2017_BU.loc['1689', MonthColumnList_G]\n",
    "building_2017_sample_E = df2017_BU.loc['1689', MonthColumnList_E]\n",
    "\n",
    "print(type(df2016_BU.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, building_2015_sample_G, ms = 5, label = 'Natural Gas usage of {} 2015'.format(buildingName_2015))\n",
    "ax.plot(month, building_2015_sample_E, ms = 5, label = 'Electricity usage of {} 2015'.format(buildingName_2015))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Natural Gas/Electricity consumption of {} in 2015'.format(buildingName_2015))\n",
    "plt.ylabel('kBTU/sq.ft')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, building_2016_sample_G, ms = 5, label = 'Natural Gas usage of {} 2016'.format(buildingName_2016))\n",
    "ax.plot(month, building_2016_sample_E, ms = 5, label = 'Electricity usage of {} 2016'.format(buildingName_2016))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Natural Gas/Electricity consumption of {} in 2016'.format(buildingName_2016))\n",
    "plt.ylabel('kBTU/sq.ft')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, building_2017_sample_G, ms = 5, label = 'Natural Gas usage of {} 2017'.format(buildingName_2017))\n",
    "ax.plot(month, building_2017_sample_E, ms = 5, label = 'Electricity usage of {} 2017'.format(buildingName_2017))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Natural Gas/Electricity consumption of {} in 2017'.format(buildingName_2017))\n",
    "plt.ylabel('kBTU/sq.ft')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save BU data\n",
    "# df2015_BU.to_csv('df2015_BU_building.csv')\n",
    "# df2016_BU.to_csv('df2016_BU_building.csv')\n",
    "# df2017_BU.to_csv('df2017_BU_building.csv')\n",
    "\n",
    "# # Processing property assessment data (2015)\n",
    "# PS_df_2015 = pd.read_csv('property-assessment-fy2015.csv', dtype = 'str')\n",
    "# PS_df_2015_BU = PS_df_2015.loc[PS_df_2015['OWNER'] == 'BOSTON UNIVERSITY TRSTS OF']\n",
    "# PS_df_2015_BU.to_csv('test_test_test_BU_2015.csv')\n",
    "\n",
    "# # Processing property assessment data (2016)\n",
    "# PS_df_2016 = pd.read_csv('property-assessment-fy2016.csv', dtype = 'str')\n",
    "# PS_df_2016_BU = PS_df_2016.loc[PS_df_2016['OWNER'] == 'BOSTON UNIVERSITY TRSTS OF']\n",
    "# PS_df_2016_BU.to_csv('test_test_test_BU_2016.csv')\n",
    "\n",
    "# # Processing property assessment data (2017)\n",
    "# PS_df_2017 = pd.read_csv('property-assessment-fy2016.csv', dtype = 'str')\n",
    "# PS_df_2017_BU = PS_df_2017.loc[PS_df_2017['OWNER'] == 'BOSTON UNIVERSITY TRSTS OF']\n",
    "# PS_df_2017_BU.to_csv('test_test_test_BU_2016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Extracting only Property Name and Year Built (2015)\n",
    "# df2015_age = pd.read_csv('df2015_BU_building.csv', usecols=[2, 12])\n",
    "# df2015_age.to_csv('df2015_age.csv')\n",
    "\n",
    "# # Extracting only Property Name and Year Built (2016)\n",
    "# df2015_age = pd.read_csv('df2016_BU_building.csv', usecols=[2, 12])\n",
    "# df2015_age.to_csv('df2016_age.csv')\n",
    "\n",
    "# # Extracting only Property Name and Year Built (2017)\n",
    "# df2015_age = pd.read_csv('df2017_BU_building.csv', usecols=[2, 12])\n",
    "# df2015_age.to_csv('df2017_age.csv')\n",
    "\n",
    "# # Extracting only Property Name and Property Uses (2015)\n",
    "# df2015_puse = pd.read_csv('df2015_BU_building.csv', usecols=[2, 11])\n",
    "# df2015_puse.to_csv('df2015_puse.csv')\n",
    "\n",
    "# # Extracting only Property Name and Property Uses (2016)\n",
    "# df2016_puse = pd.read_csv('df2016_BU_building.csv', usecols=[2, 11])\n",
    "# df2016_puse.to_csv('df2016_puse.csv')\n",
    "\n",
    "# # Extracting only Property Name and Property Uses (2017)\n",
    "# df2017_puse = pd.read_csv('df2017_BU_building.csv', usecols=[2, 11])\n",
    "# df2017_puse.to_csv('df2017_puse.csv')\n",
    "\n",
    "\n",
    "\n",
    "# New csv for factor GHGI of 2015 BU campus\n",
    "df2015_BU['GHG Intensity (kgCO2/sf)'] = pd.to_numeric(df2015_BU['GHG Intensity (kgCO2/sf)'], errors='coerce')\n",
    "# df2015_BU['GHGI'] = df2015_BU['GHG Intensity (kgCO2/sf)'] / df2015_BU['G_EUI']\n",
    "df2015_BU['GHGI'] = df2015_BU['GHG Intensity (kgCO2/sf)'] / 12\n",
    "\n",
    "\n",
    "# New csv for factor GHGI of 2016 BU campus\n",
    "df2016_BU['GHG Intensity (kgCO2/sf)'] = pd.to_numeric(df2016_BU['GHG Intensity (kgCO2/sf)'], errors='coerce')\n",
    "# df2016_BU['GHGI'] = df2016_BU['GHG Intensity (kgCO2/sf)'] / df2016_BU['G_EUI']\n",
    "df2016_BU['GHGI'] = df2016_BU['GHG Intensity (kgCO2/sf)'] / 12\n",
    "\n",
    "# New csv for factor GHGI of 2017 BU campus\n",
    "df2017_BU['GHG Intensity (kgCO2/sf)'] = pd.to_numeric(df2017_BU['GHG Intensity (kgCO2/sf)'], errors='coerce')\n",
    "# df2017_BU['GHGI'] = df2017_BU['GHG Intensity (kgCO2/sf)'] / df2017_BU['G_EUI']\n",
    "df2017_BU['GHGI'] = df2017_BU['GHG Intensity (kgCO2/sf)'] / 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extracting Water use intensity\n",
    "df2015_BU['Water Intensity (gal/sf)_num'] = pd.to_numeric(df2015_BU['Water Intensity (gal/sf)'], errors='coerce')\n",
    "df2016_BU['Water Intensity (gal/sf)_num'] = pd.to_numeric(df2016_BU['Water Intensity (gal/sf)'], errors='coerce')\n",
    "df2017_BU['Water Intensity (gal/sf)_num'] = pd.to_numeric(df2017_BU['Water Intensity (gal/sf)'], errors='coerce')\n",
    "\n",
    "df2015_BU['Water Intensity (gal/sf)_num'] /= 12\n",
    "df2016_BU['Water Intensity (gal/sf)_num'] /= 12\n",
    "df2017_BU['Water Intensity (gal/sf)_num'] /= 12\n",
    "\n",
    "\n",
    "\n",
    "# WI_2015 = df2015_BU[['Property Name', 'Water Intensity (gal/sf)_num']]\n",
    "# WI_2016 = df2016_BU[['Property Name', 'Water Intensity (gal/sf)_num']]\n",
    "# WI_2017 = df2017_BU[['Property Name', 'Water Intensity (gal/sf)_num']]\n",
    "\n",
    "# WI_2015.to_csv('Water_Intensity_2015.csv')\n",
    "# WI_2016.to_csv('Water_Intensity_2016.csv')\n",
    "# WI_2017.to_csv('Water_Intensity_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all 4 factors\n",
    "\n",
    "df2015_BU_analysis = df2015_BU[['Property Name', 'Year Built', 'Property Uses', 'Water Intensity (gal/sf)_num', 'GHGI','E_Jan','E_Feb','E_Mar','E_Apr','E_May','E_Jun','E_Jul','E_Aug','E_Sep','E_Oct','E_Nov','E_Dec', 'G_Jan','G_Feb','G_Mar','G_Apr','G_May','G_Jun','G_Jul','G_Aug','G_Sep','G_Oct','G_Nov','G_Dec']] \n",
    "df2016_BU_analysis = df2016_BU[['Property Name', 'Year Built', 'Property Uses', 'Water Intensity (gal/sf)_num', 'GHGI','E_Jan','E_Feb','E_Mar','E_Apr','E_May','E_Jun','E_Jul','E_Aug','E_Sep','E_Oct','E_Nov','E_Dec', 'G_Jan','G_Feb','G_Mar','G_Apr','G_May','G_Jun','G_Jul','G_Aug','G_Sep','G_Oct','G_Nov','G_Dec']] \n",
    "df2017_BU_analysis = df2017_BU[['Property Name', 'Year Built', 'Property Uses', 'Water Intensity (gal/sf)_num', 'GHGI','E_Jan','E_Feb','E_Mar','E_Apr','E_May','E_Jun','E_Jul','E_Aug','E_Sep','E_Oct','E_Nov','E_Dec', 'G_Jan','G_Feb','G_Mar','G_Apr','G_May','G_Jun','G_Jul','G_Aug','G_Sep','G_Oct','G_Nov','G_Dec']] \n",
    "\n",
    "# df2015_BU_analysis.to_csv('df_2015_BU_analysis.csv')\n",
    "# df2016_BU_analysis.to_csv('df_2016_BU_analysis.csv')\n",
    "# df2017_BU_analysis.to_csv('df_2017_BU_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows that contain null/inf/NaN\n",
    "\n",
    "df2015_BU_analysis = df2015_BU_analysis.replace(np.inf,np.nan)\n",
    "df2015_BU_analysis = df2015_BU_analysis.dropna(axis = 0, how = 'any')\n",
    "\n",
    "df2016_BU_analysis = df2016_BU_analysis.replace(np.inf,np.nan)\n",
    "df2016_BU_analysis = df2016_BU_analysis.dropna(axis = 0, how = 'any')\n",
    "\n",
    "df2017_BU_analysis = df2017_BU_analysis.replace(np.inf,np.nan)\n",
    "df2017_BU_analysis = df2017_BU_analysis.dropna(axis = 0, how = 'any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert property uses into numerical values\n",
    "'''\n",
    "college: 1\n",
    "sports: 2\n",
    "residentHousing: 3\n",
    "laboratory: 4\n",
    "office: 5\n",
    "hotel: 6\n",
    "distribution: 7\n",
    "food: 8\n",
    "worship: 9\n",
    "medical: 10\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def indicator_vector(df):\n",
    "    college = ['College/University', 'College/University, Office, Parking']\n",
    "    sports = ['Indoor Arena', 'Indoor Arena, Parking', 'Fitness Center/Gym', 'Other - Stadium', 'Fitness Center/Health Club/Gym, Swimming Pool']\n",
    "    residentHousing = ['Residence Hall/Dormitory', 'Parking, Residence Hall/Dormitory', 'Multifamily Housing']\n",
    "    laboratory = ['Laboratory']\n",
    "    office = ['Office', 'Office, Parking']\n",
    "    hotel = ['Hotel, Parking', 'Hotel']\n",
    "    distribution = ['Distribution Center, Office, Parking']\n",
    "    food = ['Food Service, Office']\n",
    "    worship = ['Worship Facility']\n",
    "    medical = ['Medical Office, Office']\n",
    "\n",
    "    #add columns\n",
    "    df['Uses_College'] = 0\n",
    "    df['Uses_Sports'] = 0\n",
    "    df['Uses_ResidentHousing'] = 0\n",
    "    df['Uses_Laboratory'] = 0\n",
    "    df['Uses_Office'] = 0\n",
    "    df['Uses_Hotel'] = 0\n",
    "    df['Uses_Distribution'] = 0\n",
    "    df['Uses_Food'] = 0\n",
    "    df['Uses_Worship'] = 0\n",
    "    df['Uses_Medical'] = 0\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        propertyUseStr = df.iloc[i, 2]\n",
    "    \n",
    "        if propertyUseStr in college:\n",
    "            col = df.columns.get_loc('Uses_College')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in sports:\n",
    "            col = df.columns.get_loc('Uses_Sports')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in residentHousing:\n",
    "            col = df.columns.get_loc('Uses_ResidentHousing')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in laboratory:\n",
    "            col = df.columns.get_loc('Uses_Laboratory')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in office:\n",
    "            col = df.columns.get_loc('Uses_Office')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in hotel:\n",
    "            col = df.columns.get_loc('Uses_Hotel')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in distribution:\n",
    "            col = df.columns.get_loc('Uses_Distribution')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in food:\n",
    "            col = df.columns.get_loc('Uses_Food')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in worship:\n",
    "            col = df.columns.get_loc('Uses_Worship')\n",
    "            df.iloc[i,col] = 1\n",
    "        elif propertyUseStr in medical:\n",
    "            col = df.columns.get_loc('Uses_Medical')\n",
    "            df.iloc[i,col] = 1\n",
    "        else:\n",
    "            print('Error')\n",
    "        # Should never reach this point\n",
    "    df.drop(['Property Uses'],axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "# replace Property Uses with indicator vector for 2015 data\n",
    "\n",
    "\n",
    "df2015_BU_analysis = indicator_vector(df2015_BU_analysis)\n",
    "print('df2015_BU_analysis')\n",
    "print(df2015_BU_analysis) \n",
    "print('-------------------------------------------------')\n",
    "df2016_BU_analysis = indicator_vector(df2016_BU_analysis)\n",
    "print('df2016_BU_analysis')\n",
    "print(df2016_BU_analysis) \n",
    "print('-------------------------------------------------')\n",
    "df2017_BU_analysis = indicator_vector(df2017_BU_analysis)\n",
    "print('df2017_BU_analysis')\n",
    "print(df2017_BU_analysis) \n",
    "print('-------------------------------------------------')\n",
    "    \n",
    "\n",
    "# df2015_BU_analysis.to_csv('df_2015_BU_analysis.csv')\n",
    "# df2016_BU_analysis.to_csv('df_2016_BU_analysis.csv')\n",
    "# df2017_BU_analysis.to_csv('df_2017_BU_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Data:\n",
    "\n",
    "https://www.usclimatedata.com/climate/boston/massachusetts/united-states/usma0046/2015/1\n",
    "https://www.usclimatedata.com/climate/boston/massachusetts/united-states/usma0046/2016/1\n",
    "https://www.usclimatedata.com/climate/boston/massachusetts/united-states/usma0046/2017/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data frame of weather data\n",
    "# Avg_Temp_xlsx = pd.read_excel('Avg_Temp.xlsx', index_col=None)\n",
    "# Avg_Temp_xlsx.to_csv('Avg_Temp.csv')\n",
    "\n",
    "Avg_Temp = pd.read_csv('Avg_Temp.csv', index_col=0)\n",
    "print(Avg_Temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Avg_temp to data frame\n",
    "\n",
    "for each in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']:\n",
    "    df2015_BU_analysis[each] = Avg_Temp.loc[0, each]\n",
    "\n",
    "for each in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']:\n",
    "    df2016_BU_analysis[each] = Avg_Temp.loc[1, each]\n",
    "    \n",
    "for each in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']:\n",
    "    df2017_BU_analysis[each] = Avg_Temp.loc[2, each]\n",
    "\n",
    "# df2015_BU_analysis.to_csv('df_2015_BU_analysis.csv')\n",
    "# df2016_BU_analysis.to_csv('df_2016_BU_analysis.csv') \n",
    "# df2017_BU_analysis.to_csv('df_2017_BU_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 3 years data\n",
    "df_BU_analysis_pre = df2015_BU_analysis.append(df2016_BU_analysis)\n",
    "df_BU_analysis_pre = df_BU_analysis_pre.append(df2017_BU_analysis)\n",
    "\n",
    "print(len(df_BU_analysis_pre))\n",
    "#df_BU_analysis_pre.to_csv('df_201x_BU_analysis_combined.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for selection column labels\n",
    "def returnLabelFor_T_E_G(i):\n",
    "    \n",
    "    if i > 0 and i <= 12:\n",
    "        return (MonthColumnList_T[i-1], MonthColumnList_E[i-1], MonthColumnList_G[i-1])\n",
    "    else:\n",
    "        print('Wrong!')\n",
    "        return (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce Final data set for Linear Regression Analysis\n",
    "\n",
    "# Same Algorithm for Electricity. \n",
    "# row format: [Building-Name, Month, Year, Property Uses, Temperature, WI, GHG/GAS, Age, Y_Electric]\n",
    "\n",
    "df_BU_analysis_E = pd.DataFrame()\n",
    "\n",
    "dfColumn_E = ['Temperature', 'WI', 'GHGI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical', 'Y_Electric']\n",
    "\n",
    "for _, row in df_BU_analysis_pre.iterrows():\n",
    "#     print(row['Type Index'])\n",
    "    \n",
    "    temp_df = pd.DataFrame(np.zeros((12, 15)), columns = dfColumn_E)\n",
    "        \n",
    "    temp_df['Uses_College'] = row['Uses_College']\n",
    "    temp_df['Uses_Sports'] = row['Uses_Sports']\n",
    "    temp_df['Uses_ResidentHousing'] = row['Uses_ResidentHousing']\n",
    "    temp_df['Uses_Laboratory'] = row['Uses_Laboratory']\n",
    "    temp_df['Uses_Office'] = row['Uses_Office']\n",
    "    temp_df['Uses_Hotel'] = row['Uses_Hotel']\n",
    "    temp_df['Uses_Distribution'] = row['Uses_Distribution']\n",
    "    temp_df['Uses_Food'] = row['Uses_Food']\n",
    "    temp_df['Uses_Worship'] = row['Uses_Worship']\n",
    "    temp_df['Uses_Medical'] = row['Uses_Medical']\n",
    "    \n",
    "    temp_df['Age'] = row['Year Built']\n",
    "    temp_df['GHGI'] = row['GHGI']\n",
    "    temp_df['WI'] = row['Water Intensity (gal/sf)_num']\n",
    "    \n",
    "    for i in range(0, 12):\n",
    "        (index_T, index_E, _) = returnLabelFor_T_E_G(i+1)\n",
    "        temp_df.loc[i, 'Temperature'] = row[index_T]\n",
    "        temp_df.loc[i, 'Y_Electric'] = row[index_E]\n",
    "    \n",
    "    df_BU_analysis_E = df_BU_analysis_E.append(temp_df)\n",
    "    \n",
    "\n",
    "df_BU_analysis_E.to_csv('df_201x_BU_analysis_E_Final.csv')\n",
    "      \n",
    "# print(len(df_BU_analysis_E))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same Algorithm for Gas. \n",
    "# row format: [Month, Year, Property Uses, Temperature, WI, GHG/GAS, Age, Y_Gas]\n",
    "\n",
    "df_BU_analysis_G = pd.DataFrame()\n",
    "\n",
    "dfColumn_G = ['Temperature', 'WI', 'GHGI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical', 'Y_Gas']\n",
    "\n",
    "\n",
    "for _, row in df_BU_analysis_pre.iterrows():\n",
    "#     print(row['Type Index'])\n",
    "    \n",
    "    temp_df = pd.DataFrame(np.zeros((12, 15)), columns = dfColumn_G)\n",
    "    \n",
    "    temp_df['Uses_College'] = row['Uses_College']\n",
    "    temp_df['Uses_Sports'] = row['Uses_Sports']\n",
    "    temp_df['Uses_ResidentHousing'] = row['Uses_ResidentHousing']\n",
    "    temp_df['Uses_Laboratory'] = row['Uses_Laboratory']\n",
    "    temp_df['Uses_Office'] = row['Uses_Office']\n",
    "    temp_df['Uses_Hotel'] = row['Uses_Hotel']\n",
    "    temp_df['Uses_Distribution'] = row['Uses_Distribution']\n",
    "    temp_df['Uses_Food'] = row['Uses_Food']\n",
    "    temp_df['Uses_Worship'] = row['Uses_Worship']\n",
    "    temp_df['Uses_Medical'] = row['Uses_Medical']\n",
    "    \n",
    "    temp_df['Age'] = row['Year Built']\n",
    "    temp_df['GHGI'] = row['GHGI']\n",
    "    temp_df['WI'] = row['Water Intensity (gal/sf)_num']\n",
    "    \n",
    "    for i in range(0, 12):\n",
    "        (index_T, _, index_G) = returnLabelFor_T_E_G(i+1)\n",
    "        temp_df.loc[i, 'Temperature'] = row[index_T]\n",
    "        temp_df.loc[i, 'Y_Gas'] = row[index_G]\n",
    "    \n",
    "    df_BU_analysis_G = df_BU_analysis_G.append(temp_df)\n",
    "    \n",
    "\n",
    "df_BU_analysis_G.to_csv('df_201x_BU_analysis_G_Final.csv')\n",
    "      \n",
    "# print(len(df_BU_analysis_G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Sklearn linear model to do the prediction\n",
    "linearModel_E = LinearRegression(fit_intercept=True, normalize = True)\n",
    "linearModel_G = LinearRegression(fit_intercept=True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for E and G\n",
    "print(df_BU_analysis_G.columns)\n",
    "print(df_BU_analysis_E.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Training and Testing sets for 2 regressions (Electricity, Gas)\n",
    "\n",
    "df_BU_analysis_E_shuffle = df_BU_analysis_E.sample(frac = 1)\n",
    "df_BU_analysis_G_shuffle = df_BU_analysis_G.sample(frac = 1)\n",
    "\n",
    "num_e = int(len(df_BU_analysis_E_shuffle)*0.9)\n",
    "num_g = int(len(df_BU_analysis_G_shuffle)*0.9)\n",
    "\n",
    "df_BU_training_E = df_BU_analysis_E_shuffle.iloc[:num_e, :]\n",
    "df_BU_testing_E = df_BU_analysis_E_shuffle.iloc[num_e:, :]\n",
    "\n",
    "df_BU_training_G = df_BU_analysis_G_shuffle.iloc[:num_g, :]\n",
    "df_BU_testing_G = df_BU_analysis_G_shuffle.iloc[num_g:, :]\n",
    "\n",
    "\n",
    "X_column = ['Temperature', 'WI', 'GHGI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical']\n",
    "# X_column = ['Temperature', 'WI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical']\n",
    "\n",
    "\n",
    "# Traning Data\n",
    "X_E = df_BU_training_E[X_column]\n",
    "X_G = df_BU_training_G[X_column]\n",
    "\n",
    "Y_E = df_BU_training_E['Y_Electric']\n",
    "Y_G = df_BU_training_G['Y_Gas']\n",
    "\n",
    "\n",
    "# Testing Data\n",
    "X_E_test = df_BU_testing_E[X_column]\n",
    "X_G_test = df_BU_testing_G[X_column]\n",
    "\n",
    "Y_E_test = df_BU_testing_E['Y_Electric']\n",
    "Y_G_test = df_BU_testing_G['Y_Gas']\n",
    "\n",
    "print('BU_data shape')\n",
    "print(df_BU_analysis_E.shape)\n",
    "print(df_BU_analysis_G.shape)\n",
    "print(df_BU_analysis_E_shuffle.shape)\n",
    "print(df_BU_analysis_G_shuffle.shape)\n",
    "\n",
    "print()\n",
    "print('Training Data Shape:')\n",
    "print(X_E.shape)\n",
    "print(X_G.shape)\n",
    "print()\n",
    "print(Y_E.shape)\n",
    "print(Y_G.shape)\n",
    "\n",
    "\n",
    "print()\n",
    "print('Testing Data Shape:')\n",
    "print(X_E_test.shape)\n",
    "print(X_G_test.shape)\n",
    "print()\n",
    "print(Y_E_test.shape)\n",
    "print(Y_G_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the regression:\n",
    "\n",
    "X_column = ['Temperature', 'WI', 'GHGI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical']\n",
    "# X_column = ['Temperature', 'WI', 'Age', 'Uses_College', 'Uses_Sports', 'Uses_ResidentHousing', 'Uses_Laboratory', 'Uses_Office', 'Uses_Hotel', 'Uses_Distribution', 'Uses_Food', 'Uses_Worship', 'Uses_Medical']\n",
    "\n",
    "\n",
    "linearModel_E.fit(X_E, Y_E)\n",
    "linearModel_G.fit(X_G, Y_G)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print('E: Parameters')\n",
    "print(linearModel_E.coef_.shape)\n",
    "print(linearModel_E.intercept_)\n",
    "\n",
    "print()\n",
    "print('G: Parameters')\n",
    "print(linearModel_G.coef_.shape)\n",
    "print(linearModel_G.intercept_)\n",
    "\n",
    "\n",
    "coef_E = linearModel_E.coef_\n",
    "coef_G = linearModel_G.coef_\n",
    "\n",
    "coef_E = coef_E.reshape(coef_E.shape[0], 1)\n",
    "coef_G = coef_G.reshape(coef_G.shape[0], 1)\n",
    "\n",
    "df_coef_E = pd.DataFrame(coef_E.T, columns = X_column)\n",
    "df_coef_G = pd.DataFrame(coef_G.T, columns = X_column)\n",
    "\n",
    "df_coef_E['Const'] = linearModel_E.intercept_\n",
    "df_coef_G['Const'] = linearModel_G.intercept_\n",
    "# print(df_coef_E)\n",
    "# print()\n",
    "# print(df_coef_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef_E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#predicted comments according to wights\n",
    "def to_pred(f_coef,f_data):\n",
    "    # feature dot product with weights\n",
    "    # feature f_data from testing group\n",
    "    # weight f_coef from training\n",
    "    # predicted comments \n",
    "    constant = f_coef.loc[0,'Const']\n",
    "    f_coef.drop(['Const'], axis = 1, inplace= True)\n",
    "    f_coef = f_coef.T\n",
    "    pred = np.dot(f_data,f_coef)\n",
    "    pred = pred + constant\n",
    "    return pred\n",
    "\n",
    "\n",
    "#prediction of testing group \n",
    "\n",
    "y_pred_E = to_pred(df_coef_E,X_E_test)\n",
    "y_pred_G = to_pred(df_coef_G,X_G_test)\n",
    "\n",
    "\n",
    "#true value of testing group\n",
    "y_true_E = Y_E_test\n",
    "y_true_G = Y_G_test\n",
    "\n",
    "#mean squared error\n",
    "print('---------------Mean Suared Error of Electric---------------')\n",
    "print(mean_squared_error(y_true_E, y_pred_E))\n",
    "print('---------------Mean Suared Error of Gas---------------')\n",
    "print(mean_squared_error(y_true_G, y_pred_G))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Monthly Weather Distribution\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(month, Avg_Temp.iloc[0,:], ms = 5, label = 'Temperature distribution 2015')\n",
    "ax.plot(month, Avg_Temp.iloc[1,:], ms = 5, label = 'Temperature distribution 2016')\n",
    "ax.plot(month, Avg_Temp.iloc[2,:], ms = 5, label = 'Temperature distribution 2017')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Temperature Distribution over month in 2015, 2016, and 2017')\n",
    "plt.ylabel('Fahrenheit')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property Uses\n",
    "\n",
    "\n",
    "df_uses = df_BU_analysis_pre.iloc[:, 28:38]\n",
    "\n",
    "num_uses = []\n",
    "for i in range(10):\n",
    "    for j in range(len(df_uses)):\n",
    "         if df_uses.iloc[j, i] == 1:\n",
    "                if df_uses.columns[i] == 'Uses_ResidentHousing':\n",
    "                    num_uses.append('RH')\n",
    "                if df_uses.columns[i] == 'Uses_College':\n",
    "                    num_uses.append('Col')\n",
    "                if df_uses.columns[i] == 'Uses_Sports':\n",
    "                    num_uses.append('Spo')                \n",
    "                if df_uses.columns[i] == 'Uses_Laboratory':\n",
    "                    num_uses.append('Lab')\n",
    "                if df_uses.columns[i] == 'Uses_Office':\n",
    "                    num_uses.append('Offi')\n",
    "                if df_uses.columns[i] == 'Uses_Hotel':\n",
    "                    num_uses.append('Hot')\n",
    "                if df_uses.columns[i] == 'Uses_Distribution':\n",
    "                    num_uses.append('Dis')                    \n",
    "                if df_uses.columns[i] == 'Uses_Food':\n",
    "                    num_uses.append('Food')                    \n",
    "                if df_uses.columns[i] == 'Uses_Worship':\n",
    "                    num_uses.append('Wor')                    \n",
    "                if df_uses.columns[i] == 'Uses_Medical':\n",
    "                    num_uses.append('Med')                    \n",
    "                    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(num_uses,bins = 25)\n",
    "\n",
    "plt.title('BU Campus Property Uses Distribution')\n",
    "plt.ylabel('Number')\n",
    "plt.xlabel('Property Uses')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "#separate building into different group according to every 25 years more of age\n",
    "\n",
    "lst_age = list(df_BU_analysis_pre['Year Built'])\n",
    "lst_age = [int(x) for x in lst_age]\n",
    "\n",
    "\n",
    "age = min(lst_age)\n",
    "\n",
    "def grouping(min_age, max_age, lst):\n",
    "    num = 0\n",
    "    for x in lst:\n",
    "        if x >= min_age and x < max_age:\n",
    "            num += 1\n",
    "    return num\n",
    "\n",
    "# 1887 - 1912(excludeded)\n",
    "\n",
    "# 1912 - 1937(excludeded)\n",
    "\n",
    "# 1937 - 1962(excludeded)\n",
    "\n",
    "# 1962 - 1987(excludeded)\n",
    "\n",
    "# 1987 - 2012(includeded)\n",
    "\n",
    "group = []\n",
    "while age < 2013:\n",
    "    if age < 1987:\n",
    "        max_age = age + 25\n",
    "    else:\n",
    "        max_age = age + 26\n",
    "    num_age = grouping(age, max_age, lst_age)\n",
    "    group.append(num_age)\n",
    "    age = max_age\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "year = np.array(['1887-1912', '1912-1937', '1937-1962','1962-1987','1987-2012'])\n",
    "ax.vlines(year,0,group,'b')\n",
    "\n",
    "ax.plot()\n",
    "plt.title('5 Age Groups of BU Campus Building')\n",
    "plt.ylabel('Number')\n",
    "plt.xlabel('Year Group')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weights\n",
    "\n",
    "def normalize(df_coef):\n",
    "    #df_coef     -   (1, 14)\n",
    "    \n",
    "    df = df_coef.copy()\n",
    "    \n",
    "    \n",
    "    fmean = np.mean(df.iloc[0,:])\n",
    "    frange = np.amax(df.iloc[0,:]) - np.amin(df.iloc[0,:])\n",
    "\n",
    "    #Vector Subtraction\n",
    "    df.iloc[0,:] -= fmean\n",
    "\n",
    "    #Vector Division\n",
    "    df.iloc[0,:] /= frange\n",
    "\n",
    "    return df\n",
    "\n",
    "df_coef_E_norm = normalize(df_coef_E)\n",
    "df_coef_G_norm = normalize(df_coef_G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph of weights\n",
    "\n",
    "Weights = ['Temp', 'WI', 'GHGI', 'Age', 'Col', 'Spo', 'RH', 'Lab', 'Off', 'Hot', 'Dist', 'Food', 'Wor', 'Med']\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.vlines(Weights,0, df_coef_E_norm.iloc[0,:],'r')\n",
    "ax.vlines(Weights,0, df_coef_G_norm.iloc[0,:],'b')\n",
    "\n",
    "plt.title('Weights for Energy Consumption Prediction')\n",
    "plt.ylabel('Normed Weights')\n",
    "plt.xlabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
